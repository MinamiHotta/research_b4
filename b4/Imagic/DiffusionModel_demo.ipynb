{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# diffusion modelの実装\n",
        "# 参考サイト：https://qiita.com/CabbageRoll/items/7c79ae63ba417271226e"
      ],
      "metadata": {
        "id": "kgnBHq4TcxO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import random\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# ハイパラをdataclassとjsonを用いて管理\n",
        "import json\n",
        "from dataclasses import dataclass, field\n",
        "\n",
        "# 漢字生成\n",
        "# from fontTools import ttLib\n",
        "# from PIL import Image, ImageFont, ImageDraw\n",
        "\n",
        "# UNetはこちらを利用しています\n",
        "# ファイルをダウンロードしてインポートするか、コピペしてください\n",
        "# https://github.com/tcapelle/Diffusion-Models-pytorch/blob/main/modules.py\n",
        "from modules import UNet"
      ],
      "metadata": {
        "id": "zffewfGOc0uC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 今回はDiffusion Modelを理解するためなので実データの投入は後回し"
      ],
      "metadata": {
        "id": "oQEX8ptrdqsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Denoising Diffuion Probabilistic Model\n",
        "class DDPM(nn.Module):\n",
        "  def __init__(self, T, device):\n",
        "    super().__init__()\n",
        "    self.T = T\n",
        "    self.device = device\n",
        "\n",
        "    # β, αは頻出なのでイニシャライズ段階で書いておく\n",
        "    self.beta_1 = 1e-4 # ddpm reportの値，変更可能\n",
        "    self.beta_T = 0.02 # ddpm reportの値，変更可能\n",
        "\n",
        "    self.betas = torch.linspace(self.beta_1, self.beta_T, T, device=device) # 要素数，開始値，終了値，step数を指定し連番や等差数列を生成（線形補間）\n",
        "    self.alphas = 1.0 - self.betas\n",
        "    self.alphas_bars = torch.cumprod(self.alphas, dim=0) # Παi，dim=0は横方向\n",
        "\n",
        "  # 拡散過程(x_0からノイズ入りのx_tを生成)\n",
        "  def diffusion_process(self, x0, t=None):\n",
        "    if t is None:\n",
        "      # バッチの各データについてランダムに時間を決定\n",
        "      t = torch.randint(low=1, high=self.T, size=(x0.shape[0],), device=self.device) # t：[1, T]のランダムな整数値，配列の大きさは size=(batch_size, )\n",
        "    noise = torch.randn_like(x0, device=self.device)\n",
        "    alpha_bar = self.alpha_bars[t].reshape(-1,1,1,1)\n",
        "    # x_t = √(1-β_t) * x_(t-1) + √β_t * ε = √α_bar * x_0 + √(1 - α_bar) * ε\n",
        "    xt = torch.sqrt(alpha_bar) * x0 + torch.sqrt(1 - alpha_bar) * noise\n",
        "    return xt, t, noise\n",
        "\n",
        "  # 逆拡散過程\n",
        "  # MEMO: \"model\"はノイズを予測する学習済みモデル\n",
        "  # MEMO: \"img\"はノイズを除去する画像(x_T)\n",
        "  # MEMO: \"ts\"はx_Tの時刻T\n",
        "  def denoising_process(self, model, img, ts):\n",
        "    batch_size = img.shape[0]\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      time_step_bar = tqdm(reversed(range(1,ts)), leave=False, position=0)\n",
        "      for t in time_step_bar: # ts, ts-1, .... 3, 2, 1\n",
        "        # 時刻をテンソル変換　サイズは(batch_size, )\n",
        "        time_tensor = (torch.ones(batch_size, device=self.device) * t).long()\n",
        "        # ノイズを予測\n",
        "        prediction_noise = model(img, time_tensor)\n",
        "        # ノイズを少し取り除く\n",
        "        img = self._calc_denoising_one_step(img, time_tensor, prediction_noise)\n",
        "    model.train()\n",
        "\n",
        "  # TODO: なぜreshapeしているのか調べる\n",
        "  def _calc_denoising_one_step(self, img, time_tensor, prediction_noise):\n",
        "    beta = self.betas[time_tensor].reshape(-1, 1, 1, 1)\n",
        "    sqrt_alpha = torch.sqrt(self.alphas[time_tensor].reshape(-1, 1, 1, 1))\n",
        "    alpha_bar = self.alpha_bars[time_tensor].reshape(-1, 1, 1, 1)\n",
        "    sigma_t = torch.sqrt(beta)\n",
        "    noise = torch.rand_like(img, device=self.device) if time_tensor[0].item() > 1 else torch.zeros_like(img, device=self.device)\n",
        "    # x_(t-1) = 1/(√1-β_t) * (x_t - β_t / (√1-α_bar)) * ε_θ+σ_t * Z\n",
        "    img = 1 / sqrt_alpha * (img - (beta / (torch.sqrt(1 - alpha_bar))) * prediction_noise) + sigma_t * noise\n",
        "    return img"
      ],
      "metadata": {
        "id": "P4rf9RiRdiSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習コード\n",
        "# MEMO: ハイパラはdataclassで定義\n",
        "# MEMO: UNetでベースをつくる\n",
        "# MEMO: 損失関数はMSEでOK\n",
        "def ddpm_train(params):\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(f\"{device=}\")\n",
        "  log_dir = make_save_dir_and_save_params(params) # ログディレクトリの作成とパラメータの保存\n",
        "  model_path = os.path.join(log_dir, f\"model_weight_on_{device}\") # モデルの重みを保存するパスを指定\n",
        "\n",
        "  # dataset = create_dataset(params.pix, params.extst_load=True) # TODO: 使用するデータに合わせて変更\n",
        "  dataloader = torch.utils.data.DataLoader(dataset, batch_size=params.batch_size, shuffle=True, drop_last=True) # 訓練データのロード、バッチ処理やシャッフルの準備\n",
        "  ddpm = DDPM(params.time_steps, device)\n",
        "  model = UNet(params.image_ch, params.image_ch).to(device)\n",
        "  optimizer = torch.optim.AdamW(model.parameters(), lr=params.lr)\n",
        "  loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "  start_epoch = 1\n",
        "  loss_longger = []\n",
        "  loss_min = 9e+9\n",
        "\n",
        "  # 継続して計算する場合はロード\n",
        "  if params.load_file and os.path.exists(model_path):\n",
        "    model, optimizer, start_epoch, loss_longer, loss_min = load_checkpoint(params, model, optimizer, model_path, device)\n",
        "\n",
        "  model.train()\n",
        "  epoch_bar = tqdm(range(start_epoch, params.epoch + 1))\n",
        "  # MEMO: \"loss_tmp\" はエポックごとの損失の合計を保持\n",
        "  # MEMO: \"out\" はx_tとtをUNetに代入し得られた出力で，\"loss\" で元のノイズとの差を計算する\n",
        "  for epoch in epoch_bar:\n",
        "    epoch_bar.set_description(f\"Epoch:{epoch}\")\n",
        "    loss_tmp = 0\n",
        "    iter_bar = tqdm(dataloader, leave=False)\n",
        "    for iter, x in enumerate(iter_bar): # 各バッチごとの処理\n",
        "      x = x.to(device)\n",
        "      xt, t, noise = ddpm.diffusion_process(x)\n",
        "      out = model(xt, t)\n",
        "      loss = loss_fn(noise, out)\n",
        "      optimizer.zero_grad() # 以前のバッチで計算された勾配を初期化\n",
        "      loss.backward() # 損失を逆伝播し各パラメータの勾配を計算\n",
        "      optimizer.step() # パラメータ更新\n",
        "\n",
        "      iter_bar.set_postfix({\"loss=\":f\"{loss.item():.2e}\"})\n",
        "      loss_tmp += loss.item()\n",
        "\n",
        "    loss_logger.append(loss_tmp / (iter + 1)) # 各エポックでの損失を記録\n",
        "    epoch_bar.set_postfix({\"loss=\": f\"{loss_logger[-1]:.2e}\"}) # 進捗バーの右側に最新のエポックでの損失値を表示\n",
        "\n",
        "    # 保存処理\n",
        "    # lossの経過グラフを出力\n",
        "    save_loss_logger_and_graph(log_dir, loss_logger)\n",
        "    if loss_min >= loss_logger[-1]:\n",
        "      torch.save({'epoch': epoch,\n",
        "                  'model_state_dict': model.state_dict(),\n",
        "                  'optimizer_state_dict': optimizer.state_dict(),\n",
        "                  'loss': loss_logger,\n",
        "                  }, model_path\n",
        "      )\n",
        "      loss_min = loss_logger[-1]\n",
        "\n",
        "    # 指定したstepで逆拡散による画像生成\n",
        "    if epoch % params.img_save_steps == 0:\n",
        "      x0 = torch.randn([32, params.image_ch, params.pix, params.pix], device=device)\n",
        "      img = ddpm.denoising_process(model, x0, params.time_steps).to(\"cpu\")\n",
        "      save_images_plt(img, log_dir=log_dir, epoch=epoch)\n",
        "\n",
        "# ここからコピペ\n",
        "def load_checkpoint(params, model, optimizer, model_parh, device):\n",
        "  print(f\"load model {model_path}\")\n",
        "  checkpoint = torch.load(model_path, map_location=device)\n",
        "  model.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  start_epoch = checkpoint['epoch']\n",
        "  loss_logger = checkpoint[\"loss\"]\n",
        "  loss_min = min(loss_logger)\n",
        "  print(start_epoch)\n",
        "  return model, optimizer, start_epoch, loss_logger, loss_min\n",
        "\n",
        "def make_save_dir_and_save_params(params):\n",
        "    # タスクの保存フォルダ\n",
        "    log_dir = os.path.join(r\"./\", \"log\", params.task_name)\n",
        "    os.makedirs(log_dir, exist_ok=True)\n",
        "    # epoch, iter毎のデータは多くなるので別フォルダを作る\n",
        "    log_dir_hist = os.path.join(log_dir, \"hist\")\n",
        "    os.makedirs(log_dir_hist, exist_ok=True)\n",
        "    # 設定ファイルの保存\n",
        "    with open(os.path.join(log_dir, \"parameters.json\"), 'w') as f:\n",
        "        json.dump(vars(params), f, indent=4)\n",
        "    return log_dir\n",
        "\n",
        "def save_loss_logger_and_graph(log_dir, loss_logger):\n",
        "    # loss履歴情報を保管しつつ、グラフにして画像としても書き出す\n",
        "    torch.save(loss_logger, os.path.join(log_dir, \"loss_logger.pt\"))\n",
        "    fig, ax = plt.subplots(1,1)\n",
        "    epoch = range(len(loss_logger))\n",
        "    ax.plot(epoch, loss_logger, label=\"train_loss\")\n",
        "    ax.set_ylim(0, loss_logger[-1]*5)\n",
        "    ax.legend()\n",
        "    fig.savefig(os.path.join(log_dir, \"loss_history.jpg\"))\n",
        "    plt.clf()\n",
        "    plt.close()\n",
        "\n",
        "def save_images_plt(images, log_dir, epoch, s=2):\n",
        "    # 生成した画像を並べた図を作成して保存する\n",
        "    num_img = images.shape[0]\n",
        "    img_arr = 255 - images.detach().numpy()\n",
        "    num_row = int(num_img ** 0.5)\n",
        "    num_col = (num_img - 1) // num_row + 1\n",
        "    fig, ax = plt.subplots(num_row, num_col,\n",
        "                          figsize=(num_col*s, num_row*s),\n",
        "                          tight_layout=True,\n",
        "                          sharex=True, sharey=True )\n",
        "    axs = ax.ravel() if num_img > 1 else [ax]\n",
        "    for i, img in enumerate(img_arr):\n",
        "        if img.shape[0] == 1:\n",
        "            img = img[0, :, :]\n",
        "            axs[i].imshow(img, cmap=\"gray\")\n",
        "        else:\n",
        "            img = np.transpose(img, [1, 2, 0])\n",
        "            axs[i].imshow(img)\n",
        "    if isinstance(epoch, int):\n",
        "        epoch = f\"{epoch:06d}\"\n",
        "    fig.suptitle(f\"epoch={epoch}\", size=15)\n",
        "    fig.savefig(os.path.join(log_dir, \"hist\", f\"kanji_imgs_epoch_{epoch}.jpg\"))\n",
        "    fig.savefig(os.path.join(log_dir, f\"kanji_imgs_epoch_latest.jpg\"))\n",
        "    plt.clf()\n",
        "    plt.close()\n",
        "\n",
        "@dataclass # TODO: タスクによって変更\n",
        "class HyperParameters:\n",
        "    task_name: str = \"kanji_diffusion\"\n",
        "    epochs: int = 500\n",
        "    img_save_steps: int = 10\n",
        "    batch_size: int = 128\n",
        "    lr: float = 3e-4\n",
        "    time_steps: int = 1000  # T もう少し小さくても良いはず\n",
        "    load_file: bool = True\n",
        "    pix: int = 32\n",
        "    font_file: str = r\"./ヒラギノ角ゴシック W5.ttc\"\n",
        "    image_ch: int = 1\n"
      ],
      "metadata": {
        "id": "heL7_HoWpeCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = HyperParameters()\n",
        "ddqm_train(params)"
      ],
      "metadata": {
        "id": "JXOCnxw0i2xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 拡散過程をお試し"
      ],
      "metadata": {
        "id": "lRYJr99FizZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習結果をお試し"
      ],
      "metadata": {
        "id": "FVGAQVrqpcPF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}